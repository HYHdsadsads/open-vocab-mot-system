"""å¼€æ”¾è¯æ±‡å¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿå…¥å£ - ä¼˜åŒ–ç‰ˆ"""
import cv2
import os
import sys
import argparse
import torch
from pathlib import Path

from pipeline.system import OpenVocabMOTSystem
from config import DATASET_CONFIG, MODEL_CONFIG


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å¼€æ”¾è¯æ±‡å¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ')
    parser.add_argument('--video', type=str, default=None,
                        help='è¾“å…¥è§†é¢‘è·¯å¾„')
    parser.add_argument('--output', type=str, default='./output_video.mp4',
                        help='è¾“å‡ºè§†é¢‘è·¯å¾„')
    parser.add_argument('--classes', type=str, nargs='+',
                        default=["person", "car", "bicycle", "motorcycle"],
                        help='ç›®æ ‡ç±»åˆ«åˆ—è¡¨')
    parser.add_argument('--device', type=str, default='auto',
                        choices=['auto', 'cuda', 'cpu'],
                        help='è¿è¡Œè®¾å¤‡')
    parser.add_argument('--batch-size', type=int, default=2,
                        help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--experiment', action='store_true',
                        help='å¯ç”¨å®éªŒæ¨¡å¼ï¼ˆè¯¦ç»†æ—¥å¿—ï¼‰')
    parser.add_argument('--visualize', action='store_true', default=True,
                        help='å¯è§†åŒ–è·Ÿè¸ªç»“æœ')
    parser.add_argument('--use-yolo-rd', action='store_true',
                        help='ä½¿ç”¨ YOLO-RD æ£€ç´¢å¢å¼ºæ£€æµ‹')
    parser.add_argument('--use-knowledge-tracker', action='store_true',
                        help='ä½¿ç”¨çŸ¥è¯†å¢å¼ºè·Ÿè¸ªå™¨')
    
    return parser.parse_args()


def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("=" * 60)
    print("ğŸ” ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥ CUDA
    cuda_available = torch.cuda.is_available()
    print(f"CUDA å¯ç”¨: {'âœ…' if cuda_available else 'âŒ'}")
    if cuda_available:
        print(f"CUDA è®¾å¤‡: {torch.cuda.get_device_name(0)}")
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    
    # æ£€æŸ¥ Python ç‰ˆæœ¬
    print(f"Python ç‰ˆæœ¬: {sys.version.split()[0]}")
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    yolo_path = MODEL_CONFIG["yolo_model_path"]
    if os.path.exists(yolo_path):
        print(f"âœ… YOLO æ¨¡å‹: {yolo_path}")
    else:
        print(f"âš ï¸ YOLO æ¨¡å‹æœªæ‰¾åˆ°: {yolo_path}")
    
    print("=" * 60 + "\n")


def create_test_video_if_needed(video_path: str) -> str:
    """å¦‚æœè§†é¢‘ä¸å­˜åœ¨ï¼Œåˆ›å»ºæµ‹è¯•è§†é¢‘"""
    if video_path and os.path.exists(video_path):
        return video_path
    
    print("âš ï¸ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæµ‹è¯•è§†é¢‘...")
    
    import numpy as np
    
    output_path = "test_video.mp4"
    width, height = 640, 480
    fps = 30
    duration = 5
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    for i in range(duration * fps):
        frame = np.ones((height, width, 3), dtype=np.uint8) * 255
        
        # æ·»åŠ ç§»åŠ¨çš„ç›®æ ‡
        x1 = int(100 + i * 0.5) % (width - 50)
        cv2.rectangle(frame, (x1, 200), (x1 + 50, 280), (0, 255, 0), -1)
        cv2.putText(frame, "Person", (x1, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        x2 = int(400 - i * 0.7) % (width - 100)
        cv2.rectangle(frame, (x2, 300), (x2 + 100, 350), (0, 255, 255), -1)
        cv2.putText(frame, "Car", (x2, 290), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        out.write(frame)
    
    out.release()
    print(f"âœ… æµ‹è¯•è§†é¢‘å·²åˆ›å»º: {output_path}\n")
    
    return output_path


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_args()
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_environment()
    
    # ç¡®å®šè®¾å¤‡
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device
    
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # å‡†å¤‡è§†é¢‘è·¯å¾„
    video_path = args.video
    if not video_path:
        video_path = os.path.join(DATASET_CONFIG["base_dir"], "test_video.mp4")
    
    video_path = create_test_video_if_needed(video_path)
    
    # åˆå§‹åŒ–è·Ÿè¸ªç³»ç»Ÿ
    print("=" * 60)
    print("ğŸš€ åˆå§‹åŒ–è·Ÿè¸ªç³»ç»Ÿ")
    print("=" * 60)
    print(f"ç›®æ ‡ç±»åˆ«: {', '.join(args.classes)}")
    print(f"æ‰¹å¤„ç†å¤§å°: {args.batch_size}")
    print(f"å®éªŒæ¨¡å¼: {'å¯ç”¨' if args.experiment else 'ç¦ç”¨'}")
    print(f"YOLO-RD: {'å¯ç”¨' if args.use_yolo_rd else 'ç¦ç”¨'}")
    print(f"çŸ¥è¯†å¢å¼ºè·Ÿè¸ª: {'å¯ç”¨' if args.use_knowledge_tracker else 'ç¦ç”¨'}")
    print("=" * 60 + "\n")
    
    try:
        mot_system = OpenVocabMOTSystem(
            args.classes,
            experiment_mode=args.experiment,
            batch_size=args.batch_size
        )
        
        # å¤„ç†è§†é¢‘
        print("ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘...\n")
        results = mot_system.process_video(
            video_path,
            output_path=args.output,
            visualize=args.visualize
        )
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        if results:
            print("\n" + "=" * 60)
            print("ğŸ“Š å¤„ç†ç»Ÿè®¡")
            print("=" * 60)
            print(f"æ€»å¸§æ•°: {len(results)}")
            
            # ç»Ÿè®¡è½¨è¿¹
            all_track_ids = set()
            for frame_result in results:
                for obj in frame_result:
                    all_track_ids.add(obj['track_id'])
            
            print(f"æ€»è½¨è¿¹æ•°: {len(all_track_ids)}")
            
            # ç»Ÿè®¡ç±»åˆ«
            class_counts = {}
            for frame_result in results:
                for obj in frame_result:
                    cls = obj.get('class_name', 'unknown')
                    class_counts[cls] = class_counts.get(cls, 0) + 1
            
            print("\nç±»åˆ«ç»Ÿè®¡:")
            for cls, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"  {cls}: {count}")
            
            # æ€§èƒ½æŒ‡æ ‡
            if mot_system.perf_metrics:
                print("\næ€§èƒ½æŒ‡æ ‡:")
                for metric, values in mot_system.perf_metrics.items():
                    if values:
                        import numpy as np
                        print(f"  {metric}: {np.mean(values):.4f}s (å¹³å‡)")
            
            print("=" * 60)
            print(f"âœ… å¤„ç†å®Œæˆ! è¾“å‡º: {args.output}")
            print("=" * 60 + "\n")
        else:
            print("âš ï¸ æœªç”Ÿæˆè·Ÿè¸ªç»“æœ")
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
"""
å¿«é€Ÿæµ‹è¯•ä¼˜åŒ–åŠŸèƒ½ - å¢å¼ºç‰ˆ
"""
import torch
import numpy as np
import sys
import time

print("=" * 80)
print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–åŠŸèƒ½ - å¢å¼ºç‰ˆ")
print("=" * 80)

# æµ‹è¯•ç¯å¢ƒ
print(f"\nğŸ“‹ ç¯å¢ƒä¿¡æ¯:")
print(f"   Python: {sys.version.split()[0]}")
print(f"   PyTorch: {torch.__version__}")
print(f"   CUDA: {'âœ… å¯ç”¨' if torch.cuda.is_available() else 'âŒ ä¸å¯ç”¨'}")
if torch.cuda.is_available():
    print(f"   GPU: {torch.cuda.get_device_name(0)}")

test_results = {
    "passed": 0,
    "failed": 0,
    "errors": []
}

# æµ‹è¯• 1: YOLO-RD
print("\n1ï¸âƒ£ æµ‹è¯• YOLO-RD (æ£€ç´¢å¢å¼ºæ£€æµ‹)...")
test_start = time.time()
try:
    from models.yolo_rd import DomainDictionary
    import clip
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    clip_model, _ = clip.load("ViT-B/32", device=device)
    
    domain_dict = DomainDictionary(clip_model, device, enable_cache=True)
    domain_dict.build_from_classes("test", ["person", "car", "bicycle"])
    
    # æµ‹è¯•æ£€ç´¢åŠŸèƒ½
    test_embedding = np.random.randn(512)
    test_embedding = test_embedding / np.linalg.norm(test_embedding)
    results = domain_dict.retrieve_similar(test_embedding, "test", top_k=2)
    
    assert len(results) <= 2, "æ£€ç´¢ç»“æœæ•°é‡é”™è¯¯"
    assert all(isinstance(r, tuple) and len(r) == 2 for r in results), "æ£€ç´¢ç»“æœæ ¼å¼é”™è¯¯"
    
    test_time = time.time() - test_start
    print(f"   âœ… YOLO-RD æ¨¡å—æ­£å¸¸ ({test_time:.2f}s)")
    test_results["passed"] += 1
except Exception as e:
    print(f"   âŒ YOLO-RD æµ‹è¯•å¤±è´¥: {e}")
    test_results["failed"] += 1
    test_results["errors"].append(f"YOLO-RD: {str(e)}")

# æµ‹è¯• 2: Knowledge DeepSORT
print("\n2ï¸âƒ£ æµ‹è¯• Knowledge DeepSORT (çŸ¥è¯†å¢å¼ºè·Ÿè¸ª)...")
test_start = time.time()
try:
    from tracking.knowledge_deepsort import KnowledgeEnhancedFeatureExtractor, KnowledgeDeepSORT
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    feature_extractor = KnowledgeEnhancedFeatureExtractor(device=device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    visual_feat = torch.randn(2, 512).to(device)
    semantic_feat = torch.randn(2, 512).to(device)
    
    with torch.no_grad():
        output = feature_extractor(visual_feat, semantic_feat)
    
    assert output.shape == (2, 256), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {output.shape}"
    
    # æµ‹è¯•è·Ÿè¸ªå™¨
    from models.yolo_rd import DomainDictionary
    import clip
    clip_model, _ = clip.load("ViT-B/32", device=device)
    domain_dict = DomainDictionary(clip_model, device)
    
    tracker = KnowledgeDeepSORT(domain_dict, device=device)
    assert hasattr(tracker, 'stats'), "è·Ÿè¸ªå™¨ç¼ºå°‘ç»Ÿè®¡åŠŸèƒ½"
    
    test_time = time.time() - test_start
    print(f"   âœ… Knowledge DeepSORT æ¨¡å—æ­£å¸¸ ({test_time:.2f}s)")
    test_results["passed"] += 1
except Exception as e:
    print(f"   âŒ Knowledge DeepSORT æµ‹è¯•å¤±è´¥: {e}")
    test_results["failed"] += 1
    test_results["errors"].append(f"Knowledge DeepSORT: {str(e)}")

# æµ‹è¯• 3: è¾¹ç¼˜ä¼˜åŒ–
print("\n3ï¸âƒ£ æµ‹è¯•è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–...")
test_start = time.time()
try:
    from optimization.edge_optimization import OperatorFusionAnalyzer, QuantizationStrategy, EdgeOptimizationPipeline
    
    # åˆ›å»ºç®€å•æµ‹è¯•æ¨¡å‹
    class TestModel(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.conv = torch.nn.Conv2d(3, 64, 3)
            self.bn = torch.nn.BatchNorm2d(64)
            self.relu = torch.nn.ReLU()
            self.fc = torch.nn.Linear(64, 10)
        
        def forward(self, x):
            x = self.relu(self.bn(self.conv(x)))
            x = torch.nn.functional.adaptive_avg_pool2d(x, (1, 1))
            x = x.view(x.size(0), -1)
            x = self.fc(x)
            return x
    
    model = TestModel()
    
    # æµ‹è¯•ç®—å­èåˆåˆ†æ
    fusion_analyzer = OperatorFusionAnalyzer(model)
    fusion_report = fusion_analyzer.generate_fusion_report()
    
    assert "total_fusion_opportunities" in fusion_report, "èåˆæŠ¥å‘Šæ ¼å¼é”™è¯¯"
    print(f"   âœ… å‘ç° {fusion_report['total_fusion_opportunities']} ä¸ªèåˆæœºä¼š")
    
    # æµ‹è¯•é‡åŒ–ç­–ç•¥
    device = "cuda" if torch.cuda.is_available() else "cpu"
    quant_strategy = QuantizationStrategy(model, device)
    dummy_input = torch.randn(1, 3, 32, 32)
    
    fp32_result = quant_strategy.benchmark_fp32(dummy_input, num_runs=10)
    assert "avg_latency_ms" in fp32_result, "åŸºå‡†æµ‹è¯•ç»“æœæ ¼å¼é”™è¯¯"
    print(f"   âœ… FP32 å»¶è¿Ÿ: {fp32_result['avg_latency_ms']:.2f} ms")
    
    # æµ‹è¯•å®Œæ•´æµç¨‹
    pipeline = EdgeOptimizationPipeline(model, device)
    assert hasattr(pipeline, 'run_full_optimization_analysis'), "ç¼ºå°‘å®Œæ•´åˆ†ææ–¹æ³•"
    
    test_time = time.time() - test_start
    print(f"   âœ… è¾¹ç¼˜ä¼˜åŒ–æ¨¡å—æ­£å¸¸ ({test_time:.2f}s)")
    test_results["passed"] += 1
except Exception as e:
    print(f"   âŒ è¾¹ç¼˜ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
    test_results["failed"] += 1
    test_results["errors"].append(f"è¾¹ç¼˜ä¼˜åŒ–: {str(e)}")

# æµ‹è¯• 4: å¯è§†åŒ–
print("\n4ï¸âƒ£ æµ‹è¯•å¯è§†åŒ–å·¥å…·...")
test_start = time.time()
try:
    from visualization.optimization_plots import OptimizationVisualizer
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = {
        "breakdown_chart": {
            "labels": ["Convolution", "Linear", "Activation"],
            "values": [45.0, 30.0, 25.0],
            "percentages": [45.0, 30.0, 25.0]
        },
        "quantization_comparison": {
            "fp32": {"avg_latency_ms": 100.0, "model_size_mb": 400.0},
            "fp16": {"avg_latency_ms": 55.0, "model_size_mb": 200.0, "speedup": 1.8},
            "int8": {"avg_latency_ms": 35.0, "model_size_mb": 100.0, "speedup": 2.9}
        },
        "fusion_analysis": {
            "fusion_stats": {"Conv+BN+ReLU": 5, "Linear+ReLU": 3},
            "total_fusion_opportunities": 8,
            "memory_saved_mb": 15.5
        }
    }
    
    visualizer = OptimizationVisualizer(test_data)
    
    # æµ‹è¯•å„ä¸ªç»˜å›¾æ–¹æ³•å­˜åœ¨
    assert hasattr(visualizer, 'plot_latency_breakdown_pie'), "ç¼ºå°‘é¥¼å›¾æ–¹æ³•"
    assert hasattr(visualizer, 'plot_quantization_comparison'), "ç¼ºå°‘é‡åŒ–å¯¹æ¯”æ–¹æ³•"
    assert hasattr(visualizer, 'plot_fusion_analysis'), "ç¼ºå°‘èåˆåˆ†ææ–¹æ³•"
    assert hasattr(visualizer, 'generate_all_plots'), "ç¼ºå°‘æ‰¹é‡ç”Ÿæˆæ–¹æ³•"
    
    test_time = time.time() - test_start
    print(f"   âœ… å¯è§†åŒ–å·¥å…·æ­£å¸¸ ({test_time:.2f}s)")
    test_results["passed"] += 1
except Exception as e:
    print(f"   âŒ å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
    test_results["failed"] += 1
    test_results["errors"].append(f"å¯è§†åŒ–: {str(e)}")

print("\n" + "=" * 80)
print("ğŸ“Š æµ‹è¯•æ€»ç»“")
print("=" * 80)
print(f"âœ… é€šè¿‡: {test_results['passed']}")
print(f"âŒ å¤±è´¥: {test_results['failed']}")

if test_results["errors"]:
    print("\né”™è¯¯è¯¦æƒ…:")
    for error in test_results["errors"]:
        print(f"  - {error}")

if test_results["failed"] == 0:
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
else:
    print(f"\nâš ï¸ {test_results['failed']} ä¸ªæµ‹è¯•å¤±è´¥")

print("=" * 80)
print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
print("  1. è¿è¡Œå®Œæ•´å®éªŒ: python experiments/run_optimization_experiments.py")
print("  2. æŸ¥çœ‹æ–‡æ¡£: cat OPTIMIZATION_README.md")
print("  3. è¿è¡Œä¸»ç¨‹åº: python main.py --help")
print("=" * 80 + "\n")

sys.exit(0 if test_results["failed"] == 0 else 1)
